# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12hqHA-w6fcKExir6OTuAs_9W1likaQrp
"""

import pandas as pd

# Load JSON data into a Pandas DataFrame
df = pd.read_json('E:\Care-connect\Model\cleaned_data.json')


# Display the first few rows of the DataFrame
print(df.head())

import matplotlib.pyplot as plt
import numpy as np
import pandas as pd
from sklearn import tree
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix
from sklearn.compose import ColumnTransformer
from sklearn.pipeline import Pipeline
from sklearn.impute import SimpleImputer
from sklearn.ensemble import RandomForestRegressor
# Modelling
from imblearn.over_sampling import SMOTE
from sklearn.metrics import accuracy_score, roc_auc_score
from sklearn.model_selection import RepeatedStratifiedKFold, cross_validate
from sklearn.multiclass import (
    OneVsOneClassifier,
    OneVsRestClassifier,
    OutputCodeClassifier,
)

import xgboost as xgb
from xgboost import XGBClassifier
from imblearn.under_sampling import RandomUnderSampler
from imblearn.over_sampling import RandomOverSampler
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay
from sklearn.model_selection import RandomizedSearchCV, train_test_split
from scipy.stats import randint
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, ConfusionMatrixDisplay
from sklearn.model_selection import RandomizedSearchCV
import warnings as wr

wr.filterwarnings('ignore')
print('Libraries Imported')

# Create new features or derive additional features

X = df.iloc[:, :-2].values
y = df.iloc[:, -2:].values


# Creating a new DataFrame with column names
columns_to_keep = df.columns[:-2]  # Exclude the last two columns
new_data_X = pd.DataFrame(X, columns=columns_to_keep)

column_names_y = df.columns[-2:]  # Assuming you want to use the original column names
new_data_y = pd.DataFrame(y, columns=column_names_y)

new_data_y['dropout combined']=0

new_data_y.loc[new_data_y['ANC'] < 4, 'dropout combined'] = 1
new_data_y.loc[new_data_y['PNC'] == 0, 'dropout combined'] = 2

new_data_y.drop(['ANC','PNC'], axis=1, inplace=True)

from sklearn.model_selection import train_test_split
from xgboost import XGBClassifier

# Split data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(new_data_X, new_data_y, test_size=0.2, random_state=42)

# Initialize XGBoost classifier
model = XGBClassifier()

# Print information about the model
print(model)

model.fit(X_train, y_train)

from sklearn.metrics import accuracy_score

# Make predictions on the testing data
y_pred = model.predict(X_test)

# Evaluate model performance using appropriate metrics (e.g., accuracy)
accuracy = accuracy_score(y_test, y_pred)
print("Accuracy:", accuracy)

# Save the trained model to a file for deployment
import joblib
joblib.dump(model, 'trained_model.pkl')

def predict_dropout():
    # Load the trained model
    model = joblib.load('trained_model.pkl')

    # Ask the user to input the variables
    user_input = []
    for column in new_data_X.columns:
        value = input(f"Please enter {column}: ")
        user_input.append(float(value))

    #Convert user input into a numpy array and reshape it
    user_input = np.array(user_input).reshape(1, -1)

    # Make a prediction
    prediction = model.predict(user_input)

    # Return the prediction
    return prediction

prediction = predict_dropout()

print("Predicted dropout stage:", prediction)

